\section{Конструкторская часть}
\subsection{Формат входных данных}
В качестве входных данных выступает пользовательское описание какого-либо объекта. Оно должно соответствовать следующим требованиям:
\begin{enumerate}
	\item определение даётся полностью на русском языке;
	\item недопустимо использование аббревиатур, сокращений и т.д., все слова должны быть употреблены в полной форме;
	\item описание должно укладываться в 1-2 предложения;
	\item следует связно излагать свои мысли;
	\item допускается голосовой ввод, результат которого в дальнейшем будет преобразован в текстовый формат. \newline
\end{enumerate}

\subsection{Формат выходных данных}
Выходные данные представляются как множество терминов из выборки, каждому из которых поставлены в соответствие величина косинусного сходства и её промасштабированное значение, выраженное в процентах.

Если в ходе работы метода дополнительно привлекалась сеть синтаксических графов, то пользователю также предоставляется информация о количестве совпавших слов (в запросе пользователя и терминах сети) и процентное соотношение. 

Для интерпретации полученных значений косинусного сходства и количества совпавших слов используется функция softmax \cite{softmax} позволяющая перевести множество полученных значений в вектор процентов уверенности в том, что был описан соответствующий термин. \newline

\subsection{IDEF0}
Разрабатываемый метод состоит из нескольких этапов, которые представлены на рисунках \ref{fig20:image}-\ref{fig22:image}. Необходимо по изложению пользователя определить описываемый объект. 

Эта задача решается в несколько этапов: обработка запроса клиента, его преобразование, путём извлечения ключевых слов, сопоставление полученных данных с уже имеющимися онтологиями (сформированными на базе статистики и синтаксических графов), формирование промежуточного результата, и затем -- принятие решения о том, какой именно термин (один или несколько) наиболее подходит под это описание.


В методе используется два подхода: статистический и на основе семантической сети, для каждого из них формируется онтология, процесс создания которой состоит из нескольких последовательных шагов.

Так формирование онтологии, в основе которой лежит статистические данные, представлено на рисунках \ref{fig23:image}-\ref{fig24:image}. 

\subsubsection{Алгоритм предобработки данных}\label{sec:preprocess}
На рисунке \ref{fig28:image} представлена схема алгоритма обработки данных.

В процессе нормализации всё переводится в нижний регистр, удаляются все символы, кроме, букв русского языка, между словами выставляется фиксированно только один пробел.

\subsubsection{Алгоритм создания онтологии на основе синтаксических графов}
Из-за того, что в большинстве инструментов для определения словосочетаний заложены принципы, которые определил Теньер, для решения поставленной задачи необходимо идентифицировать служебные части речи. 

В случае обнаружения и наличия зависимых от них слов, менять у детей этого элемента идентификатор родителя на идентификатор родителя для обрабатываемого слова. Таким образом, в синтаксическом дереве будут только слова, которые так или иначе несут смысловую нагрузку. 


\subsubsection{Алгоритм построения сети}
Сеть строится из синтаксических графов. При их слиянии необходимо следить за тем, чтобы не было дублирующих узлов (то есть, узлов, ассоциированных с одним и тем же словом). 

При обнаружении повторяющихся единиц, необходимо слить полезную информацию в уже существующий в графе узел.


\newpage

\subsubsection{Алгоритм поиска косинусного сходства}

\subsubsection{Алгоритм поиска по сети}
В качестве структуры данных используется дек, который позволяет добавлять элементы как в <<голову>>, так и в <<хвост>>. 

По умолчанию сеть обходится в ширину (элемент снимается с головы, добавляется в хвост), причём каждое слово, связанное с обрабатываемым узел, проверяется на наличие в пользовательском вводе. Как только находится слово, присутствующее в обеих структурах, то потомки этого узла добавляются в голову дека (инициирование обхода в глубину) и увеличивается счётчик количества совпавших  слов.

Так происходит до тех пор, пока дек не опустеет. На рисунке \ref{fig36:image} подробно изложен этот алгоритм.

\newpage

\subsection{ER-диаграмма}
На рисунках \ref{fig37:image}-\ref{fig38:image} представлены ER-диаграммы для двух рассматриваемых онтологий. 

Сущность ключевого слова (Word) содержит такие поля, как название (name) и вес (weight). Из таких элементов состоит сущность Term (термин), в нём также хранится само название термина.

NodeTerm -- узел графа, который помимо названия объекта, с которым он связан, содержит информацию о его признаках, действиях, свойствах и т.д. Кроме того, хранится информация о терминах, в которых было употреблено данное слово (mentions). 

Согласно ранее установленным условиям, помимо того, что один граф может состоять из нескольких узлов, один узел может относиться к нескольким графам. 
Сущность сети включает как идентификационную информацию, так и информацию о её составляющих.


\newpage

\subsection{Use-case диаграмма}
На рисунке \ref{fig39:image} продемонстрирована Use-case диаграмма, на которой наглядно показаны возможности каждого из участников. Выделяются две роли: пользователь и администратор. 

Для обоих предлагается два способа ввести запрос: через текстовое поле или через голосовой ввод. У обоих есть возможность просмотреть подробные результаты запроса  и локальную сеть запроса, если она была использована в методе.

Администратор, в отличие от пользователя, может вносить изменения в обе онтологии, и менять данные как по отдельным терминам, так и по всем сразу.

Дополнительно он может увидеть наглядное изображение всей сети и \, определения терминов из словаря.

\subsection*{Выводы}
%\addcontentsline{toc}{subsection}{Выводы}
В текущем разделе был определён формат входных и выходных данных, предоставлены IDEF0 схемы, подробные схемы основных алгоритмов, use-case диаграмма.
